{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YFinanceDataHandler User Guide\n",
    "\n",
    "This notebook provides a comprehensive guide to using the `YFinanceDataHandler` class from the `algoshort` package.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Installation](#1-setup-and-installation)\n",
    "2. [Basic Usage](#2-basic-usage)\n",
    "3. [Downloading Data](#3-downloading-data)\n",
    "4. [Accessing and Manipulating Data](#4-accessing-and-manipulating-data)\n",
    "5. [Massive Download Example](#5-massive-download-example)\n",
    "6. [Saving and Loading Data](#6-saving-and-loading-data)\n",
    "7. [Continuing with Algoshort Workflow](#7-continuing-with-algoshort-workflow)\n",
    "8. [Cache Management](#8-cache-management)\n",
    "9. [Best Practices](#9-best-practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, ensure you have the required packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed (uncomment to run)\n",
    "# !pip install yfinance pandas numpy pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path if running from notebooks folder\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Import YFinanceDataHandler\n",
    "from algoshort.yfinance_handler import YFinanceDataHandler\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Usage\n",
    "\n",
    "### 2.1 Creating a Handler Instance\n",
    "\n",
    "The handler can be initialized with various options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic initialization (no caching)\n",
    "handler_basic = YFinanceDataHandler()\n",
    "print(f\"Basic handler: {handler_basic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced initialization with caching and custom settings\n",
    "handler = YFinanceDataHandler(\n",
    "    cache_dir=\"../data/cache\",      # Directory for caching downloaded data\n",
    "    enable_logging=True,             # Enable logging output\n",
    "    chunk_size=50,                   # Symbols per download batch\n",
    "    log_level=logging.INFO           # Logging verbosity\n",
    ")\n",
    "print(f\"Advanced handler: {handler}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Understanding Period and Interval Options\n",
    "\n",
    "The handler supports both yfinance native formats and user-friendly aliases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available period options\n",
    "print(\"Period Options:\")\n",
    "print(\"-\" * 50)\n",
    "for alias, yf_period in handler.period_map.items():\n",
    "    print(f\"  '{alias}' -> '{yf_period}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available interval options\n",
    "print(\"\\nInterval Options:\")\n",
    "print(\"-\" * 50)\n",
    "for alias, yf_interval in handler.interval_map.items():\n",
    "    print(f\"  '{alias}' -> '{yf_interval}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Downloading Data\n",
    "\n",
    "### 3.1 Single Symbol Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for a single symbol\n",
    "data = handler.download_data(\n",
    "    symbols='AAPL',\n",
    "    period='1y',        # 1 year of data\n",
    "    interval='1d',      # Daily intervals\n",
    "    use_cache=True      # Use cached data if available\n",
    ")\n",
    "\n",
    "print(f\"Downloaded data for: {list(data.keys())}\")\n",
    "print(f\"\\nAAPL data shape: {data['AAPL'].shape}\")\n",
    "data['AAPL'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Multiple Symbols Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for multiple symbols\n",
    "tech_stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\n",
    "\n",
    "data = handler.download_data(\n",
    "    symbols=tech_stocks,\n",
    "    period='2y',\n",
    "    interval='daily',   # Using user-friendly alias\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "print(f\"Downloaded {len(data)} symbols\")\n",
    "for symbol, df in data.items():\n",
    "    print(f\"  {symbol}: {len(df)} rows, columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Download with Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download with specific date range\n",
    "data = handler.download_data(\n",
    "    symbols='SPY',\n",
    "    start='2022-01-01',\n",
    "    end='2023-12-31',\n",
    "    interval='1d'\n",
    ")\n",
    "\n",
    "spy_data = data['SPY']\n",
    "print(f\"SPY data from {spy_data.index.min()} to {spy_data.index.max()}\")\n",
    "print(f\"Total trading days: {len(spy_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Accessing and Manipulating Data\n",
    "\n",
    "### 4.1 Get Data for a Single Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all data for a symbol\n",
    "aapl_data = handler.get_data('AAPL')\n",
    "print(f\"AAPL data shape: {aapl_data.shape}\")\n",
    "aapl_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get specific columns only\n",
    "aapl_prices = handler.get_data('AAPL', columns=['open', 'close', 'volume'])\n",
    "print(f\"Columns: {list(aapl_prices.columns)}\")\n",
    "aapl_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Get OHLC Data (Analysis-Ready Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OHLC data formatted for analysis\n",
    "ohlc = handler.get_ohlc_data('AAPL')\n",
    "print(f\"OHLC columns: {list(ohlc.columns)}\")\n",
    "print(f\"Index name: {ohlc.index.name}\")\n",
    "ohlc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Combined Data (Long Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get combined data for multiple symbols (long/row-bound format)\n",
    "combined = handler.get_combined_data(\n",
    "    symbols=['AAPL', 'MSFT', 'GOOGL'],\n",
    "    columns=['close', 'volume']\n",
    ")\n",
    "\n",
    "print(f\"Combined data shape: {combined.shape}\")\n",
    "print(f\"Columns: {list(combined.columns)}\")\n",
    "print(f\"\\nUnique symbols: {combined['symbol'].unique()}\")\n",
    "combined.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Multiple Symbols Data (Wide Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data in wide format (each symbol as a column)\n",
    "wide_data = handler.get_multiple_symbols_data(\n",
    "    symbols=['AAPL', 'MSFT', 'GOOGL'],\n",
    "    column='close'\n",
    ")\n",
    "\n",
    "print(f\"Wide format shape: {wide_data.shape}\")\n",
    "print(f\"Columns: {list(wide_data.columns)}\")\n",
    "wide_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Get Company Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get company info\n",
    "info = handler.get_info('AAPL')\n",
    "\n",
    "# Display key information\n",
    "key_fields = ['longName', 'sector', 'industry', 'marketCap', 'trailingPE', 'dividendYield']\n",
    "for field in key_fields:\n",
    "    if field in info:\n",
    "        print(f\"{field}: {info[field]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Massive Download Example\n",
    "\n",
    "This section demonstrates how to download data for a large number of symbols efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a large list of symbols (S&P 500 subset + other markets)\n",
    "# In production, you might load this from a file\n",
    "\n",
    "SP500_SAMPLE = [\n",
    "    # Technology\n",
    "    'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NVDA', 'TSLA', 'AMD', 'INTC', 'CRM',\n",
    "    'ADBE', 'ORCL', 'CSCO', 'AVGO', 'TXN', 'QCOM', 'IBM', 'NOW', 'AMAT', 'MU',\n",
    "    \n",
    "    # Finance\n",
    "    'JPM', 'BAC', 'WFC', 'GS', 'MS', 'C', 'AXP', 'BLK', 'SCHW', 'USB',\n",
    "    \n",
    "    # Healthcare\n",
    "    'UNH', 'JNJ', 'PFE', 'ABBV', 'MRK', 'LLY', 'TMO', 'ABT', 'DHR', 'BMY',\n",
    "    \n",
    "    # Consumer\n",
    "    'WMT', 'PG', 'KO', 'PEP', 'COST', 'HD', 'MCD', 'NKE', 'SBUX', 'TGT',\n",
    "    \n",
    "    # Industrial\n",
    "    'CAT', 'BA', 'HON', 'UPS', 'GE', 'MMM', 'LMT', 'RTX', 'DE', 'UNP',\n",
    "    \n",
    "    # ETFs and Indices\n",
    "    'SPY', 'QQQ', 'IWM', 'DIA', 'VTI', 'VOO', 'XLF', 'XLK', 'XLE', 'XLV'\n",
    "]\n",
    "\n",
    "print(f\"Total symbols to download: {len(SP500_SAMPLE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a handler optimized for massive downloads\n",
    "massive_handler = YFinanceDataHandler(\n",
    "    cache_dir=\"../data/massive_cache\",  # Cache directory\n",
    "    enable_logging=True,\n",
    "    chunk_size=25,                       # Smaller chunks for stability\n",
    "    log_level=logging.INFO\n",
    ")\n",
    "\n",
    "print(f\"Handler ready: {massive_handler}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Massive download with progress tracking\n",
    "print(f\"Starting download of {len(SP500_SAMPLE)} symbols...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "data = massive_handler.download_data(\n",
    "    symbols=SP500_SAMPLE,\n",
    "    period='5y',           # 5 years of historical data\n",
    "    interval='1d',         # Daily data\n",
    "    use_cache=True,        # Use cache to avoid re-downloading\n",
    "    threads=True           # Enable multi-threading\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDownload complete!\")\n",
    "print(f\"Successfully downloaded: {len(data)} symbols\")\n",
    "print(f\"Failed symbols: {len(SP500_SAMPLE) - len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary of downloaded data\n",
    "summary = massive_handler.list_available_data()\n",
    "\n",
    "print(f\"\\nData Summary ({len(summary)} symbols):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Show sample\n",
    "for i, (symbol, info) in enumerate(list(summary.items())[:10]):\n",
    "    print(f\"{symbol:6s} | Rows: {info['rows']:5d} | Range: {info['date_range']} | Missing: {info['missing_values']}\")\n",
    "\n",
    "if len(summary) > 10:\n",
    "    print(f\"... and {len(summary) - 10} more symbols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and Loading Data\n",
    "\n",
    "### 6.1 Save to Different Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "from pathlib import Path\n",
    "output_dir = Path(\"../data/saved\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Save as separate files (one file per symbol)\n",
    "massive_handler.save_data(\n",
    "    filepath=str(output_dir / \"stocks.parquet\"),\n",
    "    symbols=['AAPL', 'MSFT', 'GOOGL'],\n",
    "    format='parquet',\n",
    "    multi_symbol_strategy='separate_files'\n",
    ")\n",
    "\n",
    "print(\"Saved as separate parquet files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 2: Save as single combined file\n",
    "massive_handler.save_data(\n",
    "    filepath=str(output_dir / \"tech_combined.csv\"),\n",
    "    symbols=['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META'],\n",
    "    format='csv',\n",
    "    multi_symbol_strategy='single_file',\n",
    "    combine_column='close'\n",
    ")\n",
    "\n",
    "print(\"Saved as combined CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 3: Save as Excel with multiple sheets\n",
    "massive_handler.save_data(\n",
    "    filepath=str(output_dir / \"portfolio.xlsx\"),\n",
    "    symbols=['AAPL', 'MSFT', 'JPM', 'UNH', 'WMT'],\n",
    "    format='excel',\n",
    "    multi_symbol_strategy='excel_sheets'\n",
    ")\n",
    "\n",
    "print(\"Saved as Excel with sheets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ALL downloaded data as parquet (best for large datasets)\n",
    "massive_handler.save_data(\n",
    "    filepath=str(output_dir / \"all_stocks.parquet\"),\n",
    "    format='parquet',\n",
    "    multi_symbol_strategy='separate_files'\n",
    ")\n",
    "\n",
    "print(f\"Saved all {len(massive_handler)} symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved files\n",
    "print(\"\\nSaved files:\")\n",
    "for f in sorted(output_dir.glob(\"*\")):\n",
    "    size_kb = f.stat().st_size / 1024\n",
    "    print(f\"  {f.name:40s} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Loading Data Back\n",
    "\n",
    "To continue working with saved data, you can load it directly with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parquet files\n",
    "loaded_aapl = pd.read_parquet(output_dir / \"all_stocks_AAPL.parquet\")\n",
    "print(f\"Loaded AAPL: {loaded_aapl.shape}\")\n",
    "loaded_aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple symbols and combine\n",
    "symbols_to_load = ['AAPL', 'MSFT', 'GOOGL']\n",
    "loaded_data = {}\n",
    "\n",
    "for symbol in symbols_to_load:\n",
    "    file_path = output_dir / f\"all_stocks_{symbol}.parquet\"\n",
    "    if file_path.exists():\n",
    "        loaded_data[symbol] = pd.read_parquet(file_path)\n",
    "        print(f\"Loaded {symbol}: {len(loaded_data[symbol])} rows\")\n",
    "\n",
    "print(f\"\\nTotal symbols loaded: {len(loaded_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new handler with the loaded data\n",
    "# This is useful when you want to continue the algoshort workflow\n",
    "\n",
    "# First, create a handler\n",
    "resumed_handler = YFinanceDataHandler(\n",
    "    cache_dir=\"../data/massive_cache\",\n",
    "    enable_logging=True\n",
    ")\n",
    "\n",
    "# Manually inject the loaded data\n",
    "for symbol, df in loaded_data.items():\n",
    "    resumed_handler.data[symbol] = df\n",
    "    if symbol not in resumed_handler.symbols:\n",
    "        resumed_handler.symbols.append(symbol)\n",
    "\n",
    "print(f\"Resumed handler: {resumed_handler}\")\n",
    "print(f\"Available symbols: {resumed_handler.symbols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Using Cache for Session Continuity\n",
    "\n",
    "The best way to continue work across sessions is to use the built-in cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List what's in the cache\n",
    "cached_symbols = massive_handler.list_cached_symbols()\n",
    "print(f\"Cached symbols: {len(cached_symbols)}\")\n",
    "print(f\"Sample: {cached_symbols[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View detailed cache info\n",
    "cache_info = massive_handler.list_cached_data()\n",
    "print(f\"\\nCache files ({len(cache_info)}):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (filename, info) in enumerate(list(cache_info.items())[:5]):\n",
    "    print(f\"{info['symbol']:6s} | Period: {info['period']:6s} | Interval: {info['interval']:4s} | Size: {info['size_kb']:7.1f} KB | Modified: {info['last_modified'].strftime('%Y-%m-%d %H:%M')}\")\n",
    "\n",
    "if len(cache_info) > 5:\n",
    "    print(f\"... and {len(cache_info) - 5} more files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a NEW session, create handler and data loads from cache automatically\n",
    "new_session_handler = YFinanceDataHandler(\n",
    "    cache_dir=\"../data/massive_cache\",\n",
    "    enable_logging=True\n",
    ")\n",
    "\n",
    "# Download will use cache instead of re-downloading\n",
    "data = new_session_handler.download_data(\n",
    "    symbols=['AAPL', 'MSFT', 'GOOGL'],\n",
    "    period='5y',\n",
    "    interval='1d',\n",
    "    use_cache=True  # This will load from cache if available\n",
    ")\n",
    "\n",
    "print(f\"Data loaded (from cache): {list(data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Continuing with Algoshort Workflow\n",
    "\n",
    "Now that data is loaded, you can use it with other algoshort modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import other algoshort modules\n",
    "from algoshort.ohlcprocessor import OHLCProcessor\n",
    "from algoshort.signals import regime_sma, regime_breakout\n",
    "from algoshort.stop_loss import StopLossCalculator\n",
    "from algoshort.returns import ReturnsCalculator\n",
    "\n",
    "print(\"Algoshort modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Calculate Relative Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OHLC data for stock and benchmark\n",
    "stock_ohlc = new_session_handler.get_ohlc_data('AAPL')\n",
    "\n",
    "# Download benchmark if not available\n",
    "new_session_handler.download_data('SPY', period='5y', interval='1d', use_cache=True)\n",
    "benchmark_ohlc = new_session_handler.get_ohlc_data('SPY')\n",
    "\n",
    "print(f\"Stock data: {stock_ohlc.shape}\")\n",
    "print(f\"Benchmark data: {benchmark_ohlc.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate relative prices\n",
    "processor = OHLCProcessor()\n",
    "\n",
    "# Reset index to get date column\n",
    "stock_df = stock_ohlc.reset_index()\n",
    "benchmark_df = benchmark_ohlc.reset_index()\n",
    "\n",
    "relative_data = processor.calculate_relative_prices(\n",
    "    stock_data=stock_df,\n",
    "    benchmark_data=benchmark_df,\n",
    "    rebase=True\n",
    ")\n",
    "\n",
    "print(f\"Relative data columns: {list(relative_data.columns)}\")\n",
    "relative_data[['date', 'close', 'rclose']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Generate Trading Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SMA regime signal\n",
    "signal_data = regime_sma(\n",
    "    df=relative_data,\n",
    "    close_col='rclose',\n",
    "    fast_period=50,\n",
    "    slow_period=200\n",
    ")\n",
    "\n",
    "print(f\"Signal columns added: {[c for c in signal_data.columns if 'sma' in c.lower()]}\")\n",
    "signal_data[['date', 'rclose', 'sma_50_200']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate breakout signal\n",
    "signal_data = regime_breakout(\n",
    "    df=signal_data,\n",
    "    high_col='rhigh',\n",
    "    low_col='rlow',\n",
    "    window=20\n",
    ")\n",
    "\n",
    "print(f\"Breakout signal added\")\n",
    "signal_data[['date', 'rclose', 'sma_50_200', 'bo_20']].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Calculate Stop Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for stop loss calculator\n",
    "# Rename relative columns to match expected format\n",
    "stop_data = signal_data.rename(columns={\n",
    "    'ropen': 'open',\n",
    "    'rhigh': 'high',\n",
    "    'rlow': 'low',\n",
    "    'rclose': 'close'\n",
    "})\n",
    "\n",
    "# Create stop loss calculator\n",
    "stop_calc = StopLossCalculator(stop_data)\n",
    "\n",
    "# Calculate ATR-based stop loss for the SMA signal\n",
    "result = stop_calc.atr_stop_loss(\n",
    "    signal='sma_50_200',\n",
    "    window=14,\n",
    "    multiplier=2.0\n",
    ")\n",
    "\n",
    "print(f\"Stop loss column: sma_50_200_stop_loss\")\n",
    "result[['close', 'sma_50_200', 'sma_50_200_stop_loss']].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Calculate Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create returns calculator\n",
    "# Need both absolute and relative columns\n",
    "returns_data = result.copy()\n",
    "\n",
    "# Add relative columns back (prefixed with 'r')\n",
    "returns_data['ropen'] = signal_data['ropen']\n",
    "returns_data['rhigh'] = signal_data['rhigh']\n",
    "returns_data['rlow'] = signal_data['rlow']\n",
    "returns_data['rclose'] = signal_data['rclose']\n",
    "\n",
    "returns_calc = ReturnsCalculator(returns_data)\n",
    "\n",
    "# Calculate returns for the SMA signal\n",
    "final_result = returns_calc.get_returns(\n",
    "    df=returns_data,\n",
    "    signal='sma_50_200',\n",
    "    relative=False  # Using absolute prices\n",
    ")\n",
    "\n",
    "print(f\"Returns columns added:\")\n",
    "returns_cols = [c for c in final_result.columns if 'sma_50_200' in c and c != 'sma_50_200']\n",
    "print(returns_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View final results\n",
    "display_cols = ['close', 'sma_50_200', 'sma_50_200_stop_loss', \n",
    "                'sma_50_200_returns', 'sma_50_200_cumul']\n",
    "final_result[display_cols].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# Price and signal\n",
    "axes[0].plot(final_result['date'], final_result['close'], label='Price', alpha=0.7)\n",
    "axes[0].fill_between(\n",
    "    final_result['date'],\n",
    "    final_result['close'].min(),\n",
    "    final_result['close'].max(),\n",
    "    where=final_result['sma_50_200'] == 1,\n",
    "    alpha=0.3,\n",
    "    color='green',\n",
    "    label='Long Signal'\n",
    ")\n",
    "axes[0].set_ylabel('Price')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('AAPL vs SPY - SMA 50/200 Strategy')\n",
    "\n",
    "# Cumulative returns\n",
    "axes[1].plot(final_result['date'], final_result['sma_50_200_cumul'] * 100, \n",
    "             label='Strategy Returns', color='blue')\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[1].set_ylabel('Cumulative Returns (%)')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cache Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View cache status\n",
    "print(f\"Cache directory: {massive_handler.cache_dir}\")\n",
    "print(f\"Cached symbols: {len(massive_handler.list_cached_symbols())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear cache for specific symbols\n",
    "removed = massive_handler.clear_cache(symbols=['AAPL', 'MSFT'])\n",
    "print(f\"Removed {removed} cache files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear entire cache (uncomment to run)\n",
    "# removed = massive_handler.clear_cache()\n",
    "# print(f\"Removed {removed} cache files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Best Practices\n",
    "\n",
    "### 9.1 Recommended Workflow for Large Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practice workflow\n",
    "\n",
    "def create_analysis_pipeline(symbols, cache_dir=\"../data/cache\"):\n",
    "    \"\"\"\n",
    "    Create a complete analysis pipeline with proper error handling.\n",
    "    \n",
    "    Args:\n",
    "        symbols: List of stock symbols\n",
    "        cache_dir: Cache directory path\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with handler and processed data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Initialize handler with caching\n",
    "    handler = YFinanceDataHandler(\n",
    "        cache_dir=cache_dir,\n",
    "        enable_logging=True,\n",
    "        chunk_size=25  # Conservative chunk size\n",
    "    )\n",
    "    \n",
    "    # Step 2: Download data (will use cache if available)\n",
    "    try:\n",
    "        data = handler.download_data(\n",
    "            symbols=symbols,\n",
    "            period='5y',\n",
    "            interval='1d',\n",
    "            use_cache=True\n",
    "        )\n",
    "        print(f\"Successfully loaded {len(data)} symbols\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Step 3: Validate data quality\n",
    "    summary = handler.list_available_data()\n",
    "    for symbol, info in summary.items():\n",
    "        if info['missing_values'] > 0:\n",
    "            print(f\"Warning: {symbol} has {info['missing_values']} missing values\")\n",
    "    \n",
    "    return {\n",
    "        'handler': handler,\n",
    "        'data': data,\n",
    "        'summary': summary\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "result = create_analysis_pipeline(['AAPL', 'MSFT', 'GOOGL'])\n",
    "if result:\n",
    "    print(f\"\\nPipeline ready with {len(result['data'])} symbols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Tips for Production Use\n",
    "\n",
    "1. **Always use caching** - Reduces API calls and speeds up development\n",
    "2. **Use appropriate chunk sizes** - Smaller chunks (25-50) for stability, larger (100+) for speed\n",
    "3. **Handle errors gracefully** - Some symbols may fail, continue with successful ones\n",
    "4. **Save intermediate results** - Use parquet format for best performance\n",
    "5. **Monitor cache age** - Data older than 24h is automatically refreshed\n",
    "6. **Use logging** - Enable logging to track download progress and issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This guide covered:\n",
    "\n",
    "1. **Setup** - Creating handlers with various configurations\n",
    "2. **Downloading** - Single, multiple, and massive symbol downloads\n",
    "3. **Data Access** - Multiple formats (long, wide, OHLC)\n",
    "4. **Persistence** - Saving and loading data across sessions\n",
    "5. **Workflow Integration** - Using data with other algoshort modules\n",
    "6. **Cache Management** - Efficient data reuse\n",
    "\n",
    "For more information, refer to the module docstrings and the `results_analysis_yfinance_handler.md` document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
