{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Strategy Optimizer User Guide\n",
    "\n",
    "This notebook provides a comprehensive guide to using the `StrategyOptimizer` module from the `algoshort` package for parameter tuning and walk-forward analysis.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Installation](#1-setup-and-installation)\n",
    "2. [Understanding Optimization Concepts](#2-understanding-optimization-concepts)\n",
    "3. [The get_equity() Function](#3-the-get_equity-function)\n",
    "4. [StrategyOptimizer Class](#4-strategyoptimizer-class)\n",
    "5. [Grid Search Optimization](#5-grid-search-optimization)\n",
    "6. [Rolling Walk-Forward Analysis](#6-rolling-walk-forward-analysis)\n",
    "7. [Sensitivity Analysis](#7-sensitivity-analysis)\n",
    "8. [Comparing Signals](#8-comparing-signals)\n",
    "9. [Complete Workflow Integration](#9-complete-workflow-integration)\n",
    "10. [Best Practices and Tips](#10-best-practices-and-tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's import the required modules and set up logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import tempfile\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Import optimizer modules\n",
    "from algoshort.optimizer import (\n",
    "    StrategyOptimizer,\n",
    "    get_equity,\n",
    "    _worker_evaluate,\n",
    "    MIN_SEGMENT_SIZE,\n",
    "    MIN_SEGMENT_ROWS,\n",
    "    MAX_GRID_COMBINATIONS,\n",
    "    MAX_PARAM_VALUES,\n",
    ")\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "print(f\"\\nModule Constants:\")\n",
    "print(f\"  MIN_SEGMENT_SIZE: {MIN_SEGMENT_SIZE} bars\")\n",
    "print(f\"  MIN_SEGMENT_ROWS: {MIN_SEGMENT_ROWS} rows\")\n",
    "print(f\"  MAX_GRID_COMBINATIONS: {MAX_GRID_COMBINATIONS:,}\")\n",
    "print(f\"  MAX_PARAM_VALUES: {MAX_PARAM_VALUES:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Understanding Optimization Concepts\n",
    "\n",
    "### What is Strategy Optimization?\n",
    "\n",
    "Strategy optimization is the process of finding the best parameter values for a trading strategy. The `StrategyOptimizer` provides:\n",
    "\n",
    "| Method | Description | Use Case |\n",
    "|--------|-------------|----------|\n",
    "| **Grid Search** | Tests all combinations of parameter values | Finding optimal parameters on a single data segment |\n",
    "| **Walk-Forward** | Rolling optimization with in-sample/out-of-sample splits | Avoiding overfitting, realistic backtesting |\n",
    "| **Sensitivity Analysis** | Tests parameter neighborhood around best values | Validating parameter robustness |\n",
    "\n",
    "### Walk-Forward Analysis Explained\n",
    "\n",
    "Walk-forward analysis splits data into segments:\n",
    "\n",
    "```\n",
    "Data: [====================================================================================]\n",
    "\n",
    "Segment 1: [IN-SAMPLE (optimize)] [OUT-OF-SAMPLE (validate)]\n",
    "Segment 2:            [IN-SAMPLE (optimize)] [OUT-OF-SAMPLE (validate)]\n",
    "Segment 3:                        [IN-SAMPLE (optimize)] [OUT-OF-SAMPLE (validate)]\n",
    "Segment 4:                                    [IN-SAMPLE (optimize)] [OUT-OF-SAMPLE (validate)]\n",
    "```\n",
    "\n",
    "- **In-Sample (IS)**: Used to find best parameters via grid search\n",
    "- **Out-of-Sample (OOS)**: Used to validate performance with those parameters\n",
    "- This prevents overfitting by never testing on the same data used for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### Key Metrics\n",
    "\n",
    "The optimizer tracks several metrics from the equity function:\n",
    "\n",
    "| Metric | Description |\n",
    "|--------|-------------|\n",
    "| `convex` | Equity using convex risk adjustment (aggressive) |\n",
    "| `concave` | Equity using concave risk adjustment (conservative) |\n",
    "| `constant` | Equity using constant risk percentage |\n",
    "| `equal_weight` | Equity using equal weight allocation |\n",
    "\n",
    "### Parameter Stability\n",
    "\n",
    "The optimizer calculates **Coefficient of Variation (CV)** for each parameter:\n",
    "\n",
    "```\n",
    "CV = std(parameter_values) / mean(parameter_values)\n",
    "```\n",
    "\n",
    "- **Low CV** (< 0.2): Parameters are stable across segments (good)\n",
    "- **High CV** (> 0.5): Parameters vary significantly (potential overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. The get_equity() Function\n",
    "\n",
    "The `get_equity()` function processes a data segment and returns equity metrics. It's the core function used by the optimizer.\n",
    "\n",
    "### Function Signature\n",
    "\n",
    "```python\n",
    "get_equity(\n",
    "    segment_df: pd.DataFrame,      # OHLC data\n",
    "    segment_idx: int = 0,          # Segment index for logging\n",
    "    config_path: str = '...',      # Path to config JSON\n",
    "    price_col: str = 'close',      # Price column name\n",
    "    stop_method: str = 'atr',      # Stop-loss method\n",
    "    inplace: bool = False,         # Modify input DataFrame?\n",
    "    save_output: bool = False,     # Save to Excel?\n",
    "    **stop_kwargs                  # Stop-loss parameters\n",
    ") -> Dict[str, Any]\n",
    "```\n",
    "\n",
    "### Available Stop-Loss Methods\n",
    "\n",
    "| Method | Description | Key Parameters |\n",
    "|--------|-------------|----------------|\n",
    "| `atr` | ATR-based trailing stop | `window`, `multiplier` |\n",
    "| `fixed_percentage` | Fixed % below/above entry | `percentage` |\n",
    "| `breakout_channel` | Donchian channel stop | `window` |\n",
    "| `moving_average` | MA-based stop | `window`, `ma_type` |\n",
    "| `volatility_std` | Standard deviation stop | `window`, `multiplier` |\n",
    "| `support_resistance` | S/R level stop | `window` |\n",
    "| `classified_pivot` | Pivot point stop | `swing_window` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample OHLC data for demonstrations\n",
    "np.random.seed(42)\n",
    "n_days = 500  # About 2 years of trading days\n",
    "\n",
    "# Generate realistic price data\n",
    "dates = pd.date_range('2022-01-01', periods=n_days, freq='B')\n",
    "returns = np.random.normal(0.0003, 0.015, n_days)  # Daily returns\n",
    "close = 100 * np.exp(np.cumsum(returns))\n",
    "\n",
    "# Create OHLC DataFrame\n",
    "df_sample = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'open': close * (1 + np.random.uniform(-0.005, 0.005, n_days)),\n",
    "    'high': close * (1 + np.abs(np.random.normal(0, 0.01, n_days))),\n",
    "    'low': close * (1 - np.abs(np.random.normal(0, 0.01, n_days))),\n",
    "    'close': close,\n",
    "    'volume': np.random.randint(1000000, 5000000, n_days),\n",
    "})\n",
    "\n",
    "# Add benchmark for relative calculations\n",
    "benchmark_returns = np.random.normal(0.0002, 0.012, n_days)\n",
    "df_sample['rclose'] = 100 * np.exp(np.cumsum(benchmark_returns))\n",
    "\n",
    "print(f\"Sample data shape: {df_sample.shape}\")\n",
    "print(f\"Date range: {df_sample['date'].iloc[0]} to {df_sample['date'].iloc[-1]}\")\n",
    "print(f\"\\nPrice range: ${df_sample['close'].min():.2f} - ${df_sample['close'].max():.2f}\")\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary config file for demonstrations\n",
    "config = {\n",
    "    \"regimes\": {\n",
    "        \"floor_ceiling\": {\n",
    "            \"lvl\": 1,\n",
    "            \"vlty_n\": 63,\n",
    "            \"threshold\": 1.5,\n",
    "            \"dgt\": 3,\n",
    "            \"d_vol\": 1.0,\n",
    "            \"dist_pct\": 0.05,\n",
    "            \"retrace_pct\": 0.05,\n",
    "            \"r_vol\": 1.0\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save config to temp file\n",
    "config_path = tempfile.mktemp(suffix='.json')\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"Config file created: {config_path}\")\n",
    "print(f\"\\nConfig contents:\")\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Creating a Custom Equity Function\n",
    "\n",
    "For faster demonstrations, let's create a simplified equity function that doesn't require the full regime calculation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_equity_func(\n",
    "    segment_df: pd.DataFrame,\n",
    "    segment_idx: int = 0,\n",
    "    config_path: str = '',\n",
    "    price_col: str = 'close',\n",
    "    stop_method: str = 'atr',\n",
    "    **stop_kwargs\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Simplified equity function for demonstration.\n",
    "    \n",
    "    In production, use the actual get_equity() function.\n",
    "    \"\"\"\n",
    "    # Extract parameters\n",
    "    window = stop_kwargs.get('window', 14)\n",
    "    multiplier = stop_kwargs.get('multiplier', 2.0)\n",
    "    \n",
    "    # Calculate a simple performance metric based on parameters\n",
    "    # (In reality, this would run the full strategy simulation)\n",
    "    np.random.seed(segment_idx + int(window * 100 + multiplier * 10))\n",
    "    \n",
    "    # Simulate that certain parameter combinations work better\n",
    "    base_return = 0.15  # 15% base return\n",
    "    \n",
    "    # Optimal window around 14, optimal multiplier around 2.0\n",
    "    window_penalty = abs(window - 14) * 0.01\n",
    "    mult_penalty = abs(multiplier - 2.0) * 0.05\n",
    "    \n",
    "    noise = np.random.normal(0, 0.02)\n",
    "    total_return = base_return - window_penalty - mult_penalty + noise\n",
    "    \n",
    "    # Calculate equity values\n",
    "    initial_capital = 100000\n",
    "    \n",
    "    return {\n",
    "        'convex': initial_capital * (1 + total_return * 1.2),\n",
    "        'concave': initial_capital * (1 + total_return * 0.8),\n",
    "        'constant': initial_capital * (1 + total_return),\n",
    "        'equal_weight': initial_capital * (1 + total_return * 0.9),\n",
    "        'segment_idx': segment_idx,\n",
    "        'rows_processed': len(segment_df),\n",
    "        'stop_method': stop_method,\n",
    "        'window': window,\n",
    "        'multiplier': multiplier,\n",
    "    }\n",
    "\n",
    "# Test the mock function\n",
    "result = mock_equity_func(\n",
    "    segment_df=df_sample.iloc[:100],\n",
    "    segment_idx=0,\n",
    "    config_path=config_path,\n",
    "    stop_method='atr',\n",
    "    window=14,\n",
    "    multiplier=2.0\n",
    ")\n",
    "\n",
    "print(\"Mock equity function result:\")\n",
    "for key, value in result.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:,.2f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. StrategyOptimizer Class\n",
    "\n",
    "### Initialization\n",
    "\n",
    "```python\n",
    "StrategyOptimizer(\n",
    "    data: pd.DataFrame,                    # Full historical OHLC data\n",
    "    equity_func: Callable[..., Dict],      # Function to compute metrics\n",
    "    config_path: str                        # Path to config file\n",
    ")\n",
    "```\n",
    "\n",
    "### Input Validation\n",
    "\n",
    "The optimizer validates:\n",
    "- `data` must be a non-empty DataFrame\n",
    "- `equity_func` must be callable\n",
    "- `config_path` must point to an existing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer instance\n",
    "optimizer = StrategyOptimizer(\n",
    "    data=df_sample,\n",
    "    equity_func=mock_equity_func,\n",
    "    config_path=config_path\n",
    ")\n",
    "\n",
    "print(f\"Optimizer initialized successfully!\")\n",
    "print(f\"  Data rows: {len(optimizer.data)}\")\n",
    "print(f\"  Config path: {optimizer.config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation examples\n",
    "print(\"Input validation demonstrations:\\n\")\n",
    "\n",
    "# Example 1: Empty DataFrame\n",
    "try:\n",
    "    bad_optimizer = StrategyOptimizer(\n",
    "        data=pd.DataFrame(),  # Empty!\n",
    "        equity_func=mock_equity_func,\n",
    "        config_path=config_path\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"1. Empty DataFrame: {e}\")\n",
    "\n",
    "# Example 2: Non-callable equity_func\n",
    "try:\n",
    "    bad_optimizer = StrategyOptimizer(\n",
    "        data=df_sample,\n",
    "        equity_func=\"not_a_function\",  # Not callable!\n",
    "        config_path=config_path\n",
    "    )\n",
    "except TypeError as e:\n",
    "    print(f\"2. Non-callable: {e}\")\n",
    "\n",
    "# Example 3: Invalid config path\n",
    "try:\n",
    "    bad_optimizer = StrategyOptimizer(\n",
    "        data=df_sample,\n",
    "        equity_func=mock_equity_func,\n",
    "        config_path=\"nonexistent_file.json\"  # Doesn't exist!\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"3. Invalid config: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. Grid Search Optimization\n",
    "\n",
    "Grid search tests all combinations of parameter values to find the best performing set.\n",
    "\n",
    "### Method Signature\n",
    "\n",
    "```python\n",
    "optimizer.run_grid_search(\n",
    "    segment_data: pd.DataFrame,           # Data segment to evaluate\n",
    "    param_grid: Dict[str, Iterable],      # Parameter combinations\n",
    "    segment_idx: int,                      # Segment index\n",
    "    stop_method: str = 'atr',              # Stop-loss method\n",
    "    price_col: str = 'close',              # Price column\n",
    "    n_jobs: int = 1,                       # Parallel jobs (-1 for all CPUs)\n",
    "    backend: str = 'loky',                 # Joblib backend\n",
    ") -> pd.DataFrame\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'window': [10, 12, 14, 16, 18, 20],\n",
    "    'multiplier': [1.5, 1.75, 2.0, 2.25, 2.5]\n",
    "}\n",
    "\n",
    "n_combinations = 1\n",
    "for values in param_grid.values():\n",
    "    n_combinations *= len(values)\n",
    "\n",
    "print(f\"Parameter Grid:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "print(f\"\\nTotal combinations: {n_combinations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run grid search\n",
    "grid_results = optimizer.run_grid_search(\n",
    "    segment_data=df_sample,\n",
    "    param_grid=param_grid,\n",
    "    segment_idx=0,\n",
    "    stop_method='atr',\n",
    "    price_col='close',\n",
    "    n_jobs=1  # Use 1 for notebook stability; use -1 in production\n",
    ")\n",
    "\n",
    "print(f\"Grid search results: {len(grid_results)} combinations tested\")\n",
    "print(f\"\\nColumns: {list(grid_results.columns)}\")\n",
    "grid_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters\n",
    "best_idx = grid_results['convex'].idxmax()\n",
    "best_row = grid_results.loc[best_idx]\n",
    "\n",
    "print(\"Best Parameters (by convex equity):\")\n",
    "print(f\"  Window: {best_row['window']}\")\n",
    "print(f\"  Multiplier: {best_row['multiplier']}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Convex Equity: ${best_row['convex']:,.2f}\")\n",
    "print(f\"  Constant Equity: ${best_row['constant']:,.2f}\")\n",
    "print(f\"  Equal Weight Equity: ${best_row['equal_weight']:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results as heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pivot results for heatmap\n",
    "pivot = grid_results.pivot(index='window', columns='multiplier', values='convex')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "im = ax.imshow(pivot.values, cmap='RdYlGn', aspect='auto')\n",
    "\n",
    "# Set ticks\n",
    "ax.set_xticks(range(len(pivot.columns)))\n",
    "ax.set_xticklabels(pivot.columns)\n",
    "ax.set_yticks(range(len(pivot.index)))\n",
    "ax.set_yticklabels(pivot.index)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel('Multiplier')\n",
    "ax.set_ylabel('Window')\n",
    "ax.set_title('Grid Search Results: Convex Equity by Parameters')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Convex Equity ($)')\n",
    "\n",
    "# Annotate values\n",
    "for i in range(len(pivot.index)):\n",
    "    for j in range(len(pivot.columns)):\n",
    "        value = pivot.iloc[i, j]\n",
    "        text = ax.text(j, i, f'{value/1000:.1f}k', ha='center', va='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Grid Search Safety Limits\n",
    "\n",
    "The optimizer has built-in limits to prevent memory issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Exceeding combination limit\n",
    "try:\n",
    "    large_grid = {\n",
    "        'param1': list(range(100)),\n",
    "        'param2': list(range(100)),\n",
    "        'param3': list(range(10))\n",
    "    }  # 100 * 100 * 10 = 100,000 combinations\n",
    "    \n",
    "    optimizer.run_grid_search(\n",
    "        segment_data=df_sample,\n",
    "        param_grid=large_grid,\n",
    "        segment_idx=0\n",
    "    )\n",
    "except RuntimeError as e:\n",
    "    print(f\"Combination limit exceeded: {e}\")\n",
    "\n",
    "# Example: Too many values per parameter\n",
    "try:\n",
    "    too_many_values = {\n",
    "        'window': list(range(1, 1500))  # 1499 values > MAX_PARAM_VALUES\n",
    "    }\n",
    "    \n",
    "    optimizer.run_grid_search(\n",
    "        segment_data=df_sample,\n",
    "        param_grid=too_many_values,\n",
    "        segment_idx=0\n",
    "    )\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\nParameter values limit exceeded: {e}\")\n",
    "\n",
    "# Example: Empty parameter values\n",
    "try:\n",
    "    empty_values = {\n",
    "        'window': []  # Empty list!\n",
    "    }\n",
    "    \n",
    "    optimizer.run_grid_search(\n",
    "        segment_data=df_sample,\n",
    "        param_grid=empty_values,\n",
    "        segment_idx=0\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"\\nEmpty values error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 6. Rolling Walk-Forward Analysis\n",
    "\n",
    "Walk-forward analysis is the gold standard for strategy validation. It prevents overfitting by using separate data for optimization and validation.\n",
    "\n",
    "### Method Signature\n",
    "\n",
    "```python\n",
    "optimizer.rolling_walk_forward(\n",
    "    stop_method: str,                      # Stop-loss method\n",
    "    param_grid: Dict[str, Iterable],       # Parameter grid\n",
    "    close_col: str = 'close',              # Close price column\n",
    "    n_segments: int = 4,                   # Number of walk-forward segments\n",
    "    n_jobs: int = 1,                       # Parallel jobs\n",
    "    verbose: bool = False,                 # Print detailed output\n",
    "    opt_metric: str = 'convex'             # Metric to optimize\n",
    ") -> Tuple[pd.DataFrame, Dict, List]\n",
    "```\n",
    "\n",
    "### Returns\n",
    "\n",
    "1. **oos_df**: DataFrame with out-of-sample results for each segment\n",
    "2. **stability**: Dict with parameter stability metrics (CV values)\n",
    "3. **history**: List of dicts with per-segment best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run walk-forward optimization\n",
    "oos_df, stability, history = optimizer.rolling_walk_forward(\n",
    "    stop_method='atr',\n",
    "    param_grid={\n",
    "        'window': [10, 12, 14, 16, 18, 20],\n",
    "        'multiplier': [1.5, 2.0, 2.5]\n",
    "    },\n",
    "    close_col='close',\n",
    "    n_segments=4,\n",
    "    n_jobs=1,\n",
    "    verbose=True,\n",
    "    opt_metric='convex'\n",
    ")\n",
    "\n",
    "print(f\"\\nWalk-forward complete!\")\n",
    "print(f\"  OOS results: {len(oos_df)} segments\")\n",
    "print(f\"  Valid segments: {stability.get('n_segments_valid', 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View out-of-sample results\n",
    "print(\"Out-of-Sample Results:\")\n",
    "oos_df[['segment', 'convex', 'constant', 'equal_weight', 'window', 'multiplier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View parameter stability\n",
    "print(\"Parameter Stability (Coefficient of Variation):\")\n",
    "print(\"=\"*50)\n",
    "for key, value in stability.items():\n",
    "    if key == 'n_segments_valid':\n",
    "        print(f\"  Valid segments: {value}\")\n",
    "    elif '_cv' in key:\n",
    "        param_name = key.replace('_cv', '')\n",
    "        if pd.isna(value):\n",
    "            print(f\"  {param_name}: N/A\")\n",
    "        else:\n",
    "            stability_rating = \"Stable\" if value < 0.2 else \"Moderate\" if value < 0.5 else \"Unstable\"\n",
    "            print(f\"  {param_name}: {value:.4f} ({stability_rating})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View optimization history\n",
    "print(\"Optimization History (Best Parameters per Segment):\")\n",
    "print(\"=\"*60)\n",
    "for entry in history:\n",
    "    print(f\"\\nSegment {entry['segment']}:\")\n",
    "    print(f\"  In-Sample Metric: ${entry['is_metric']:,.2f}\")\n",
    "    print(f\"  Parameters: {entry['params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize walk-forward results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: OOS Performance by Segment\n",
    "ax1 = axes[0, 0]\n",
    "segments = oos_df['segment']\n",
    "width = 0.25\n",
    "x = np.arange(len(segments))\n",
    "\n",
    "ax1.bar(x - width, oos_df['convex']/1000, width, label='Convex', color='green')\n",
    "ax1.bar(x, oos_df['constant']/1000, width, label='Constant', color='blue')\n",
    "ax1.bar(x + width, oos_df['equal_weight']/1000, width, label='Equal Weight', color='orange')\n",
    "\n",
    "ax1.axhline(y=100, color='gray', linestyle='--', alpha=0.5, label='Initial Capital')\n",
    "ax1.set_xlabel('Segment')\n",
    "ax1.set_ylabel('Equity ($K)')\n",
    "ax1.set_title('Out-of-Sample Performance by Segment')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(segments)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Parameter Values Across Segments\n",
    "ax2 = axes[0, 1]\n",
    "windows = [h['params']['window'] for h in history]\n",
    "multipliers = [h['params']['multiplier'] for h in history]\n",
    "segments_hist = [h['segment'] for h in history]\n",
    "\n",
    "ax2_twin = ax2.twinx()\n",
    "ax2.plot(segments_hist, windows, 'b-o', label='Window', linewidth=2, markersize=8)\n",
    "ax2_twin.plot(segments_hist, multipliers, 'r-s', label='Multiplier', linewidth=2, markersize=8)\n",
    "\n",
    "ax2.set_xlabel('Segment')\n",
    "ax2.set_ylabel('Window', color='blue')\n",
    "ax2_twin.set_ylabel('Multiplier', color='red')\n",
    "ax2.set_title('Best Parameters per Segment')\n",
    "ax2.legend(loc='upper left')\n",
    "ax2_twin.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: IS vs OOS Performance\n",
    "ax3 = axes[1, 0]\n",
    "is_metrics = [h['is_metric'] for h in history]\n",
    "oos_metrics = oos_df['convex'].values\n",
    "\n",
    "ax3.bar(x - 0.2, np.array(is_metrics)/1000, 0.4, label='In-Sample', color='lightblue')\n",
    "ax3.bar(x + 0.2, oos_metrics/1000, 0.4, label='Out-of-Sample', color='darkblue')\n",
    "ax3.axhline(y=100, color='gray', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('Segment')\n",
    "ax3.set_ylabel('Convex Equity ($K)')\n",
    "ax3.set_title('In-Sample vs Out-of-Sample Performance')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(segments)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Stability Indicators\n",
    "ax4 = axes[1, 1]\n",
    "cv_values = {k.replace('_cv', ''): v for k, v in stability.items() if '_cv' in k}\n",
    "params = list(cv_values.keys())\n",
    "cvs = [cv_values[p] if not pd.isna(cv_values[p]) else 0 for p in params]\n",
    "\n",
    "colors = ['green' if c < 0.2 else 'orange' if c < 0.5 else 'red' for c in cvs]\n",
    "ax4.barh(params, cvs, color=colors)\n",
    "ax4.axvline(x=0.2, color='green', linestyle='--', alpha=0.5, label='Stable (<0.2)')\n",
    "ax4.axvline(x=0.5, color='red', linestyle='--', alpha=0.5, label='Unstable (>0.5)')\n",
    "ax4.set_xlabel('Coefficient of Variation')\n",
    "ax4.set_title('Parameter Stability (CV)')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## 7. Sensitivity Analysis\n",
    "\n",
    "Sensitivity analysis tests how robust your optimal parameters are by evaluating performance in the neighborhood of the best values.\n",
    "\n",
    "### Method Signature\n",
    "\n",
    "```python\n",
    "optimizer.sensitivity_analysis(\n",
    "    stop_method: str,                       # Stop-loss method\n",
    "    best_params: Dict[str, Any],            # Best parameter values\n",
    "    close_col: str = 'close',               # Close price column\n",
    "    variance: float = 0.20,                 # Fraction to vary (+/- 20%)\n",
    "    opt_metric: str = 'convex',             # Metric to evaluate\n",
    "    extra_grids: Optional[Dict] = None      # Additional grid values\n",
    ") -> Tuple[float, pd.DataFrame]\n",
    "```\n",
    "\n",
    "### Returns\n",
    "\n",
    "1. **plateau_ratio_pct**: (avg performance / peak performance) * 100\n",
    "   - High ratio (> 80%): Parameters are robust\n",
    "   - Low ratio (< 60%): Performance is sensitive to parameter changes\n",
    "2. **results_df**: Full grid search results around the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best parameters from walk-forward\n",
    "if history:\n",
    "    best_params = history[-1]['params']\n",
    "else:\n",
    "    best_params = {'window': 14, 'multiplier': 2.0}\n",
    "\n",
    "print(f\"Best parameters for sensitivity analysis: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sensitivity analysis\n",
    "plateau_ratio, sens_results = optimizer.sensitivity_analysis(\n",
    "    stop_method='atr',\n",
    "    best_params=best_params,\n",
    "    close_col='close',\n",
    "    variance=0.20,  # +/- 20%\n",
    "    opt_metric='convex'\n",
    ")\n",
    "\n",
    "print(f\"Sensitivity Analysis Results:\")\n",
    "print(f\"  Plateau Ratio: {plateau_ratio:.2f}%\")\n",
    "print(f\"  Combinations tested: {len(sens_results)}\")\n",
    "\n",
    "if plateau_ratio > 80:\n",
    "    print(f\"\\n  Interpretation: ROBUST - Performance degrades gracefully\")\n",
    "elif plateau_ratio > 60:\n",
    "    print(f\"\\n  Interpretation: MODERATE - Some sensitivity to parameters\")\n",
    "else:\n",
    "    print(f\"\\n  Interpretation: SENSITIVE - Performance highly dependent on exact parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sensitivity results\n",
    "print(\"Sensitivity Grid Results:\")\n",
    "sens_results[['window', 'multiplier', 'convex', 'constant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sensitivity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Performance by parameter value\n",
    "ax1 = axes[0]\n",
    "\n",
    "# Group by window\n",
    "for mult in sens_results['multiplier'].unique():\n",
    "    mask = sens_results['multiplier'] == mult\n",
    "    ax1.plot(sens_results[mask]['window'], sens_results[mask]['convex']/1000,\n",
    "             'o-', label=f'mult={mult}', markersize=8, linewidth=2)\n",
    "\n",
    "ax1.axhline(y=sens_results['convex'].max()/1000, color='green', linestyle='--', \n",
    "            alpha=0.5, label='Peak')\n",
    "ax1.axhline(y=sens_results['convex'].mean()/1000, color='orange', linestyle='--',\n",
    "            alpha=0.5, label='Average')\n",
    "\n",
    "ax1.set_xlabel('Window')\n",
    "ax1.set_ylabel('Convex Equity ($K)')\n",
    "ax1.set_title('Performance Sensitivity by Window')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Distribution of performance\n",
    "ax2 = axes[1]\n",
    "ax2.hist(sens_results['convex']/1000, bins=10, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=sens_results['convex'].max()/1000, color='green', linestyle='--',\n",
    "            linewidth=2, label=f'Peak: ${sens_results[\"convex\"].max()/1000:.1f}K')\n",
    "ax2.axvline(x=sens_results['convex'].mean()/1000, color='orange', linestyle='--',\n",
    "            linewidth=2, label=f'Mean: ${sens_results[\"convex\"].mean()/1000:.1f}K')\n",
    "\n",
    "ax2.set_xlabel('Convex Equity ($K)')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title(f'Performance Distribution (Plateau: {plateau_ratio:.1f}%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## 8. Comparing Signals\n",
    "\n",
    "The `compare_signals()` method runs walk-forward optimization and summarizes results.\n",
    "\n",
    "**Note**: Currently compares single signal with summary statistics. Multi-signal comparison is planned for future versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare signals\n",
    "comparison = optimizer.compare_signals(\n",
    "    signals='rrg',  # Signal name (used for labeling)\n",
    "    stop_method='atr',\n",
    "    param_grid={'window': [10, 14, 20], 'multiplier': [1.5, 2.0, 2.5]},\n",
    "    n_segments=3,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "print(\"Signal Comparison Results:\")\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## 9. Complete Workflow Integration\n",
    "\n",
    "Here's how to integrate the optimizer with the full `algoshort` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required modules\n",
    "try:\n",
    "    from algoshort.yfinance_handler import YFinanceDataHandler\n",
    "    from algoshort.stop_loss import StopLossCalculator\n",
    "    from algoshort.position_sizing import PositionSizing\n",
    "    print(\"All modules imported successfully!\")\n",
    "    FULL_INTEGRATION = True\n",
    "except ImportError as e:\n",
    "    print(f\"Some modules not available: {e}\")\n",
    "    print(\"Showing example workflow structure instead.\")\n",
    "    FULL_INTEGRATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete optimization workflow\n",
    "print(\"=\"*60)\n",
    "print(\"COMPLETE OPTIMIZATION WORKFLOW\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Define parameter space\n",
    "print(\"\\n1. DEFINE PARAMETER SPACE\")\n",
    "param_grid = {\n",
    "    'window': [10, 12, 14, 16, 18, 20],\n",
    "    'multiplier': [1.5, 1.75, 2.0, 2.25, 2.5]\n",
    "}\n",
    "print(f\"   Parameters: {list(param_grid.keys())}\")\n",
    "print(f\"   Total combinations: {len(param_grid['window']) * len(param_grid['multiplier'])}\")\n",
    "\n",
    "# Step 2: Run walk-forward optimization\n",
    "print(\"\\n2. RUN WALK-FORWARD OPTIMIZATION\")\n",
    "oos_df, stability, history = optimizer.rolling_walk_forward(\n",
    "    stop_method='atr',\n",
    "    param_grid=param_grid,\n",
    "    n_segments=4,\n",
    "    opt_metric='convex',\n",
    "    n_jobs=1\n",
    ")\n",
    "print(f\"   Valid segments: {stability.get('n_segments_valid', 0)}\")\n",
    "print(f\"   Mean OOS Convex: ${oos_df['convex'].mean():,.2f}\")\n",
    "\n",
    "# Step 3: Analyze parameter stability\n",
    "print(\"\\n3. ANALYZE PARAMETER STABILITY\")\n",
    "for key, value in stability.items():\n",
    "    if '_cv' in key:\n",
    "        param = key.replace('_cv', '')\n",
    "        if pd.isna(value):\n",
    "            print(f\"   {param} CV: N/A\")\n",
    "        else:\n",
    "            status = \"STABLE\" if value < 0.2 else \"MODERATE\" if value < 0.5 else \"UNSTABLE\"\n",
    "            print(f\"   {param} CV: {value:.4f} ({status})\")\n",
    "\n",
    "# Step 4: Get consensus best parameters\n",
    "print(\"\\n4. DETERMINE BEST PARAMETERS\")\n",
    "# Use most frequent or last segment's parameters\n",
    "if history:\n",
    "    best_params = history[-1]['params']\n",
    "    print(f\"   Best parameters: {best_params}\")\n",
    "\n",
    "# Step 5: Run sensitivity analysis\n",
    "print(\"\\n5. RUN SENSITIVITY ANALYSIS\")\n",
    "plateau_ratio, sens_results = optimizer.sensitivity_analysis(\n",
    "    stop_method='atr',\n",
    "    best_params=best_params,\n",
    "    variance=0.20\n",
    ")\n",
    "print(f\"   Plateau ratio: {plateau_ratio:.2f}%\")\n",
    "robustness = \"HIGH\" if plateau_ratio > 80 else \"MODERATE\" if plateau_ratio > 60 else \"LOW\"\n",
    "print(f\"   Robustness: {robustness}\")\n",
    "\n",
    "# Step 6: Final recommendation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMIZATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nRecommended Parameters:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nExpected Performance (OOS):\")\n",
    "print(f\"  Mean Convex Equity: ${oos_df['convex'].mean():,.2f}\")\n",
    "print(f\"  Mean Return: {(oos_df['convex'].mean() / 100000 - 1) * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nConfidence Assessment:\")\n",
    "print(f\"  Parameter Stability: {list(stability.values())[0] if stability else 'N/A'}\")\n",
    "print(f\"  Robustness (Plateau): {plateau_ratio:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "## 10. Best Practices and Tips\n",
    "\n",
    "### Data Requirements\n",
    "\n",
    "| Requirement | Minimum | Recommended |\n",
    "|-------------|---------|-------------|\n",
    "| Total rows | 100 | 500+ |\n",
    "| Rows per segment | 30 | 50+ |\n",
    "| Segments | 2 | 4-6 |\n",
    "\n",
    "### Parameter Grid Guidelines\n",
    "\n",
    "```python\n",
    "# GOOD: Reasonable grid\n",
    "param_grid = {\n",
    "    'window': [10, 14, 20, 30],        # 4 values\n",
    "    'multiplier': [1.5, 2.0, 2.5, 3.0]  # 4 values\n",
    "}  # 16 combinations\n",
    "\n",
    "# BAD: Too large\n",
    "param_grid = {\n",
    "    'window': list(range(5, 100)),     # 95 values!\n",
    "    'multiplier': np.arange(0.5, 5, 0.1)  # 45 values!\n",
    "}  # 4,275 combinations - too many!\n",
    "```\n",
    "\n",
    "### Interpreting Results\n",
    "\n",
    "| Metric | Good | Concerning |\n",
    "|--------|------|------------|\n",
    "| Parameter CV | < 0.2 | > 0.5 |\n",
    "| Plateau Ratio | > 80% | < 60% |\n",
    "| IS vs OOS Gap | < 20% | > 50% |\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "1. **Overfitting**: Using too many parameters or segments\n",
    "2. **Data Snooping**: Testing too many parameter combinations\n",
    "3. **Survivorship Bias**: Not including delisted securities\n",
    "4. **Look-Ahead Bias**: Using future data in calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference: Full optimization workflow\n",
    "print(\"\"\"\n",
    "QUICK REFERENCE: Strategy Optimization Workflow\n",
    "================================================\n",
    "\n",
    "# 1. Setup\n",
    "from algoshort.optimizer import StrategyOptimizer, get_equity\n",
    "\n",
    "optimizer = StrategyOptimizer(\n",
    "    data=df,\n",
    "    equity_func=get_equity,  # or custom function\n",
    "    config_path='config.json'\n",
    ")\n",
    "\n",
    "# 2. Walk-Forward Optimization\n",
    "oos_df, stability, history = optimizer.rolling_walk_forward(\n",
    "    stop_method='atr',\n",
    "    param_grid={'window': [10, 14, 20], 'multiplier': [1.5, 2.0, 2.5]},\n",
    "    n_segments=4,\n",
    "    opt_metric='convex'\n",
    ")\n",
    "\n",
    "# 3. Check Stability\n",
    "print(f\"Parameter stability: {stability}\")\n",
    "\n",
    "# 4. Sensitivity Analysis\n",
    "best_params = history[-1]['params']\n",
    "plateau, sens_df = optimizer.sensitivity_analysis(\n",
    "    stop_method='atr',\n",
    "    best_params=best_params,\n",
    "    variance=0.20\n",
    ")\n",
    "print(f\"Plateau ratio: {plateau:.1f}%\")\n",
    "\n",
    "# 5. Use optimized parameters in production\n",
    "print(f\"Recommended: {best_params}\")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup: Remove temporary config file\n",
    "if os.path.exists(config_path):\n",
    "    os.unlink(config_path)\n",
    "    print(f\"Temporary config file removed: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This guide covered:\n",
    "\n",
    "1. **Setup**: Import and understand the optimizer module\n",
    "2. **Concepts**: Walk-forward analysis, parameter stability, sensitivity\n",
    "3. **get_equity()**: The core equity calculation function\n",
    "4. **StrategyOptimizer**: Class initialization and validation\n",
    "5. **Grid Search**: Finding optimal parameters on a single segment\n",
    "6. **Walk-Forward**: Robust optimization with IS/OOS splits\n",
    "7. **Sensitivity**: Testing parameter robustness\n",
    "8. **Signal Comparison**: Comparing different trading signals\n",
    "9. **Integration**: Complete workflow with other modules\n",
    "10. **Best Practices**: Guidelines for effective optimization\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Always use **walk-forward analysis** to avoid overfitting\n",
    "- Check **parameter stability** (CV) across segments\n",
    "- Validate with **sensitivity analysis** before production\n",
    "- Keep parameter grids **reasonable** (< 1000 combinations)\n",
    "- Compare **IS vs OOS performance** to detect overfitting\n",
    "\n",
    "For questions or issues, refer to the test suite at `tests/test_optimizer.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
